{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import transformers\nimport pandas as pd\nfrom datasets import Dataset\nimport datasets","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:05:58.312984Z","iopub.execute_input":"2022-11-01T21:05:58.314835Z","iopub.status.idle":"2022-11-01T21:05:59.729105Z","shell.execute_reply.started":"2022-11-01T21:05:58.314760Z","shell.execute_reply":"2022-11-01T21:05:59.727811Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"! pip install datasets transformers rouge-score nltk\n","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:05:59.739385Z","iopub.execute_input":"2022-11-01T21:05:59.740079Z","iopub.status.idle":"2022-11-01T21:06:13.739555Z","shell.execute_reply.started":"2022-11-01T21:05:59.740039Z","shell.execute_reply":"2022-11-01T21:06:13.738264Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.7)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.13.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.8.2)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.10.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge-score) (0.15.0)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.15.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.0.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (8.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.1.1)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (2.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.12)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=e422c8b8af44966e1f8677915a9b72fe036049463077d2474a3492238b9306cf\n  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!apt install git-lfs","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:06:13.741771Z","iopub.execute_input":"2022-11-01T21:06:13.742956Z","iopub.status.idle":"2022-11-01T21:06:19.899902Z","shell.execute_reply.started":"2022-11-01T21:06:13.742910Z","shell.execute_reply":"2022-11-01T21:06:19.898708Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following NEW packages will be installed:\n  git-lfs\n0 upgraded, 1 newly installed, 0 to remove and 93 not upgraded.\nNeed to get 3316 kB of archives.\nAfter this operation, 11.1 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 git-lfs amd64 2.9.2-1 [3316 kB]\nFetched 3316 kB in 0s (7157 kB/s)[0m\u001b[33m\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package git-lfs.\n(Reading database ... 108827 files and directories currently installed.)\nPreparing to unpack .../git-lfs_2.9.2-1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking git-lfs (2.9.2-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up git-lfs (2.9.2-1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8Processing triggers for man-db (2.9.1-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:06:19.903133Z","iopub.execute_input":"2022-11-01T21:06:19.903473Z","iopub.status.idle":"2022-11-01T21:06:19.950234Z","shell.execute_reply.started":"2022-11-01T21:06:19.903446Z","shell.execute_reply":"2022-11-01T21:06:19.949245Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83f84a5e0c444ae396d40a2e5c6e4656"}},"metadata":{}}]},{"cell_type":"code","source":"train_set = pd.read_excel(\"../input/summarization/Competition CERIST -- Summarization/Dataset 2 Arabic + English (XL_sum)/English/dataset_XL_sum_v1.0_train_en.xlsx\")\ntest_set = pd.read_excel(\"../input/summarization/Competition CERIST -- Summarization/Dataset 2 Arabic + English (XL_sum)/English/dataset_XL_sum_v1.0_test_en.xlsx\")\ntrain_ds = Dataset.from_pandas(train_set)\ntest_ds = Dataset.from_pandas(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:06.324382Z","iopub.execute_input":"2022-11-01T21:12:06.325222Z","iopub.status.idle":"2022-11-01T21:12:48.114098Z","shell.execute_reply.started":"2022-11-01T21:12:06.325174Z","shell.execute_reply":"2022-11-01T21:12:48.113052Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_dataset, validation_dataset= train_ds.train_test_split(test_size=0.1).values()\ndata_all_splits = datasets.DatasetDict({\"train\":train_dataset,\"test\":test_ds, \"val\":validation_dataset})\n","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:48.116339Z","iopub.execute_input":"2022-11-01T21:12:48.116768Z","iopub.status.idle":"2022-11-01T21:12:48.214011Z","shell.execute_reply.started":"2022-11-01T21:12:48.116729Z","shell.execute_reply":"2022-11-01T21:12:48.212836Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from datasets import load_metric\nmetric = load_metric(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:48.215794Z","iopub.execute_input":"2022-11-01T21:12:48.216203Z","iopub.status.idle":"2022-11-01T21:12:49.686770Z","shell.execute_reply.started":"2022-11-01T21:12:48.216161Z","shell.execute_reply":"2022-11-01T21:12:49.685796Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4696a42991f41fca209b0ffcf9c54d1"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nmodel_checkpoint = \"t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:49.689842Z","iopub.execute_input":"2022-11-01T21:12:49.690568Z","iopub.status.idle":"2022-11-01T21:12:52.635091Z","shell.execute_reply.started":"2022-11-01T21:12:49.690524Z","shell.execute_reply":"2022-11-01T21:12:52.632867Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"013b662839d94374bbfc97c1e3e17ea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54b004b25a0480080cb7145a73b7dc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bd30bb1357241639a2873fa164391a7"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5_fast.py:166: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\nFor now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]:\n    prefix = \"summarize: \"\nelse:\n    prefix = \"\"","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:52.636732Z","iopub.execute_input":"2022-11-01T21:12:52.637105Z","iopub.status.idle":"2022-11-01T21:12:52.642243Z","shell.execute_reply.started":"2022-11-01T21:12:52.637068Z","shell.execute_reply":"2022-11-01T21:12:52.641194Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"max_input_length = 1024\nmax_target_length = 128\n\n\ndef preprocess_function(examples):\n    inputs = [prefix + doc for doc in examples[\"Document\"]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Setup the tokenizer for targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"Summary\"], max_length=max_target_length, truncation=True\n        )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:52.643780Z","iopub.execute_input":"2022-11-01T21:12:52.644424Z","iopub.status.idle":"2022-11-01T21:12:52.654604Z","shell.execute_reply.started":"2022-11-01T21:12:52.644376Z","shell.execute_reply":"2022-11-01T21:12:52.653572Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = data_all_splits.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:12:52.656194Z","iopub.execute_input":"2022-11-01T21:12:52.656562Z","iopub.status.idle":"2022-11-01T21:22:16.037944Z","shell.execute_reply.started":"2022-11-01T21:12:52.656527Z","shell.execute_reply":"2022-11-01T21:22:16.037003Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/275 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b207887d4aaa4c809edd3dce8f3e3d47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2762924ee9be4521a3632da815cb4324"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/31 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf39347df00443d89927015be95ec81e"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:22:16.039239Z","iopub.execute_input":"2022-11-01T21:22:16.039650Z","iopub.status.idle":"2022-11-01T21:22:16.048147Z","shell.execute_reply.started":"2022-11-01T21:22:16.039611Z","shell.execute_reply":"2022-11-01T21:22:16.047217Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Document', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 274291\n    })\n    test: Dataset({\n        features: ['Document', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 11529\n    })\n    val: Dataset({\n        features: ['Document', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 30477\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:22:16.049693Z","iopub.execute_input":"2022-11-01T21:22:16.050555Z","iopub.status.idle":"2022-11-01T21:22:34.711834Z","shell.execute_reply.started":"2022-11-01T21:22:16.050504Z","shell.execute_reply":"2022-11-01T21:22:34.710730Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"624b13f221e14887af53966b6e391c5b"}},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\nmodel_name = model_checkpoint.split(\"/\")[-1]\nargs = Seq2SeqTrainingArguments(\n    f\"{model_name}-finetuned-xsum\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=1,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:22:34.715919Z","iopub.execute_input":"2022-11-01T21:22:34.716470Z","iopub.status.idle":"2022-11-01T21:22:34.840945Z","shell.execute_reply.started":"2022-11-01T21:22:34.716441Z","shell.execute_reply":"2022-11-01T21:22:34.839945Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:22:34.842684Z","iopub.execute_input":"2022-11-01T21:22:34.843420Z","iopub.status.idle":"2022-11-01T21:22:34.856716Z","shell.execute_reply.started":"2022-11-01T21:22:34.843381Z","shell.execute_reply":"2022-11-01T21:22:34.855809Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    # Replace -100 in the labels as we can't decode them.\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    # Rouge expects a newline after each sentence\n    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n    \n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    # Extract a few results\n    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n    \n    # Add mean generated length\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n    \n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:22:34.858454Z","iopub.execute_input":"2022-11-01T21:22:34.859223Z","iopub.status.idle":"2022-11-01T21:22:34.874175Z","shell.execute_reply.started":"2022-11-01T21:22:34.859169Z","shell.execute_reply":"2022-11-01T21:22:34.873320Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"val\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\n\nhub_model_id = \"lilouuch/t5-small-finetuned-xsum\"\nsummarizer = pipeline(\"summarization\", model=hub_model_id)","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:22:34.875365Z","iopub.execute_input":"2022-11-01T21:22:34.876234Z","iopub.status.idle":"2022-11-01T21:23:00.130261Z","shell.execute_reply.started":"2022-11-01T21:22:34.876198Z","shell.execute_reply":"2022-11-01T21:23:00.129161Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbd3a4d2cb740edb346bfacde3706a8"}},"metadata":{}},{"name":"stderr","text":"2022-11-01 21:22:37.800731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:37.801749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:37.802882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:37.803653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:37.804378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:37.805115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:37.808276: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-01 21:22:38.046478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:38.047354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:38.048144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:38.048921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:38.049673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:38.050431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.901229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.902177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.902978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.903742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.904450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.905110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13351 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2022-11-01 21:22:45.908861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-01 21:22:45.909600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13351 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/231M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26294e9373dd4d35993fca29c2342689"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f97edf34c6194b0b852c22778a452992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"553156d66c4c43ad882c79a9da66a624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"718d1ae7efc3401d9393b03da8d3761b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/2.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b01662220e4977ac1cb5c12cd4a8bc"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:23:00.132131Z","iopub.execute_input":"2022-11-01T21:23:00.132591Z","iopub.status.idle":"2022-11-01T21:23:00.141487Z","shell.execute_reply.started":"2022-11-01T21:23:00.132550Z","shell.execute_reply":"2022-11-01T21:23:00.140176Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Document', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 274291\n    })\n    test: Dataset({\n        features: ['Document', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 11529\n    })\n    val: Dataset({\n        features: ['Document', 'Summary', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 30477\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"summaries=summarizer(tokenized_datasets['test']['Document'])","metadata":{"execution":{"iopub.status.busy":"2022-11-01T21:54:32.731721Z","iopub.execute_input":"2022-11-01T21:54:32.732094Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Your max_length is set to 200, but you input_length is only 171. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=85)\nYour max_length is set to 200, but you input_length is only 188. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=94)\nYour max_length is set to 200, but you input_length is only 161. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=80)\nYour max_length is set to 200, but you input_length is only 129. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=64)\nYour max_length is set to 200, but you input_length is only 171. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=85)\nYour max_length is set to 200, but you input_length is only 149. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=74)\nYour max_length is set to 200, but you input_length is only 168. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=84)\nYour max_length is set to 200, but you input_length is only 168. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=84)\nYour max_length is set to 200, but you input_length is only 121. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=60)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}